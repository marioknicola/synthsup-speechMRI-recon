{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0278a5bb",
   "metadata": {},
   "source": [
    "# Cross-Validation Training for U-Net MRI Super-Resolution\n",
    "\n",
    "## Recommended Workflow for 7 Subjects\n",
    "\n",
    "**Strategy:** 6-fold CV + 1 held-out subject\n",
    "\n",
    "1. **Hold out 1 subject** (e.g., Subject 0021) for final testing\n",
    "2. **6-fold CV** on remaining 6 subjects (e.g., 0022-0027)\n",
    "   - Each fold: Train on 5, test on 1\n",
    "   - Gives 6 models with independent test performance\n",
    "3. **Select best fold** based on average test metrics (PSNR/SSIM)\n",
    "4. **Test best model** on held-out subject (0021)\n",
    "\n",
    "**Why this approach?**\n",
    "- ‚úÖ Unbiased model selection (held-out never seen)\n",
    "- ‚úÖ 6 models provide robust performance estimate\n",
    "- ‚úÖ Best model gets final test on fresh subject\n",
    "- ‚úÖ Standard practice for limited subjects\n",
    "\n",
    "**Before starting:**\n",
    "1. Prepare data as ZIP files (`Synth_LR_nii.zip` and `HR_nii.zip`)\n",
    "2. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "3. Upload ZIP files when prompted (Section 2)\n",
    "\n",
    "**After training:**\n",
    "- Download results from `/content/cross_validation_results/`\n",
    "- Files ‚Üí Left panel ‚Üí Right-click folder ‚Üí Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa7e73",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3c980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GPU not available! Enable: Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c171db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!cd /content && git clone https://github.com/marioknicola/synthsup-speechMRI-recon.git\n",
    "%cd /content/synthsup-speechMRI-recon\n",
    "!pip install -q -r requirements.txt\n",
    "print(\"‚úÖ Repository cloned and dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda4b93",
   "metadata": {},
   "source": [
    "## 2. Upload and Extract Data\n",
    "\n",
    "Upload your data as ZIP files for faster transfer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e19d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload ZIP files\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"UPLOAD DATA\")\n",
    "print(\"=\"*70)\n",
    "print(\"Please upload 2 ZIP files:\")\n",
    "print(\"  1. Synth_LR_nii.zip  ‚Üí Input/LR images\")\n",
    "print(\"  2. HR_nii.zip        ‚Üí Target/HR images\")\n",
    "print(\"\\nClick 'Choose Files' below...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "uploaded = files.upload()\n",
    "print(f\"\\n‚úÖ Uploaded {len(uploaded)} file(s)\")\n",
    "\n",
    "# Extract ZIP files\n",
    "INPUT_DIR = \"/content/data/Synth_LR_nii\"\n",
    "TARGET_DIR = \"/content/data/HR_nii\"\n",
    "OUTPUT_DIR = \"/content/cross_validation_results\"  # Local storage only\n",
    "\n",
    "os.makedirs(\"/content/data\", exist_ok=True)\n",
    "\n",
    "print(\"\\nExtracting ZIP files...\")\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"  Extracting {filename}...\")\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"/content/data\")\n",
    "    os.remove(filename)  # Clean up ZIP file\n",
    "    print(f\"    Done!\")\n",
    "\n",
    "# Verify extraction\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if os.path.exists(INPUT_DIR):\n",
    "    input_files = [f for f in os.listdir(INPUT_DIR) if f.endswith('.nii')]\n",
    "    print(f\"‚úÖ Input: {len(input_files)} files\")\n",
    "    print(f\"   Location: {INPUT_DIR}\")\n",
    "    print(f\"   Sample: {input_files[:3]}\")\n",
    "else:\n",
    "    print(f\"‚ùå Input directory not found: {INPUT_DIR}\")\n",
    "    print(f\"   Make sure Synth_LR_nii folder is in the ZIP\")\n",
    "\n",
    "if os.path.exists(TARGET_DIR):\n",
    "    target_files = [f for f in os.listdir(TARGET_DIR) if f.endswith('.nii')]\n",
    "    print(f\"‚úÖ Target: {len(target_files)} files\")\n",
    "    print(f\"   Location: {TARGET_DIR}\")\n",
    "    print(f\"   Sample: {target_files[:3]}\")\n",
    "else:\n",
    "    print(f\"‚ùå Target directory not found: {TARGET_DIR}\")\n",
    "    print(f\"   Make sure HR_nii folder is in the ZIP\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"\\n‚úÖ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"   (Stored locally in Colab - download results after training)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795f573",
   "metadata": {},
   "source": [
    "## 3. Define Subjects and CV Strategy\n",
    "\n",
    "**For 7 subjects:** 6-fold CV + 1 held-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed396d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ CONFIGURE YOUR 7 SUBJECTS\n",
    "ALL_SUBJECTS = ['0021', '0022', '0023', '0024', '0025', '0026', '0027']\n",
    "\n",
    "# ‚úÖ CHOOSE HELD-OUT SUBJECT (will NOT be used in CV)\n",
    "HELD_OUT_SUBJECT = '0021'  # Final test subject, never seen during CV\n",
    "\n",
    "# Subjects for 6-fold CV (excluding held-out)\n",
    "CV_SUBJECTS = [s for s in ALL_SUBJECTS if s != HELD_OUT_SUBJECT]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENTAL DESIGN: 6-FOLD CV + HELD-OUT SUBJECT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüì¶ Held-out subject: {HELD_OUT_SUBJECT}\")\n",
    "print(f\"   ‚Üí Will be used for FINAL testing only\")\n",
    "print(f\"   ‚Üí Never seen by any model during training\")\n",
    "print(f\"\\nüîÑ CV subjects: {CV_SUBJECTS}\")\n",
    "print(f\"   ‚Üí Used for 6-fold cross-validation\")\n",
    "print(f\"   ‚Üí Each model trains on 5, tests on 1\")\n",
    "print(f\"\\nüìä Workflow:\")\n",
    "print(f\"   1. Train 6 models (6-fold CV on {len(CV_SUBJECTS)} subjects)\")\n",
    "print(f\"   2. Select best model based on CV test performance\")\n",
    "print(f\"   3. Test best model on held-out subject ({HELD_OUT_SUBJECT})\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416324a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 6-fold CV on CV subjects (excludes held-out)\n",
    "cv_folds = []\n",
    "for i, test_subject in enumerate(CV_SUBJECTS, 1):\n",
    "    train_subjects = [s for s in CV_SUBJECTS if s != test_subject]\n",
    "    cv_folds.append({\n",
    "        'fold_name': f'fold{i}',\n",
    "        'train': train_subjects,\n",
    "        'test': [test_subject]\n",
    "    })\n",
    "\n",
    "# Display folds\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"6-FOLD CROSS-VALIDATION SPLITS\")\n",
    "print(\"=\"*70)\n",
    "for fold in cv_folds:\n",
    "    print(f\"\\n{fold['fold_name']}:\")\n",
    "    print(f\"  Train (n=5): {fold['train']}\")\n",
    "    print(f\"  Test  (n=1): {fold['test']}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"‚ö†Ô∏è  Subject {HELD_OUT_SUBJECT} is NOT in any fold\")\n",
    "print(f\"   It will be tested AFTER selecting the best fold\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f70b0d",
   "metadata": {},
   "source": [
    "## 4. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387fd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ CONFIGURE TRAINING PARAMETERS\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs': 200,\n",
    "    'batch_size': 4,\n",
    "    'lr': 1e-5,\n",
    "    'base_filters': 32,\n",
    "    'loss_alpha': 0.7  # 70% MSE + 30% SSIM\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\"*40)\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key:15s}: {value}\")\n",
    "print(\"=\"*40)\n",
    "print(\"\\nüíæ Model Saving: Only best model per fold (saves storage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a36fc",
   "metadata": {},
   "source": [
    "## 5. Train All Folds\n",
    "\n",
    "This will train all 6 folds sequentially:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17344f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all folds\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for fold in cv_folds:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"TRAINING: {fold['fold_name'].upper()}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Build command\n",
    "    cmd = f\"python train_cross_validation.py \"\n",
    "    cmd += f\"--train-subjects {' '.join(fold['train'])} \"\n",
    "    cmd += f\"--test-subjects {' '.join(fold['test'])} \"\n",
    "    cmd += f\"--fold-name {fold['fold_name']} \"\n",
    "    cmd += f\"--input-dir '{INPUT_DIR}' \"\n",
    "    cmd += f\"--target-dir '{TARGET_DIR}' \"\n",
    "    cmd += f\"--output-dir '{OUTPUT_DIR}' \"\n",
    "    cmd += f\"--epochs {TRAINING_CONFIG['epochs']} \"\n",
    "    cmd += f\"--batch-size {TRAINING_CONFIG['batch_size']} \"\n",
    "    cmd += f\"--lr {TRAINING_CONFIG['lr']} \"\n",
    "    cmd += f\"--base-filters {TRAINING_CONFIG['base_filters']} \"\n",
    "    cmd += f\"--loss-alpha {TRAINING_CONFIG['loss_alpha']}\"\n",
    "    \n",
    "    # Execute\n",
    "    !{cmd}\n",
    "    \n",
    "    print(f\"\\n‚úÖ Completed {fold['fold_name']}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL FOLDS COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total training time: {total_time/3600:.2f} hours\")\n",
    "print(f\"Average per fold: {total_time/len(cv_folds)/3600:.2f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82723c6",
   "metadata": {},
   "source": [
    "## 6. Evaluate and Select Best Fold\n",
    "\n",
    "After all folds are trained, evaluate which performed best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6290014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect test performance from all folds\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for fold in cv_folds:\n",
    "    history_file = os.path.join(OUTPUT_DIR, fold['fold_name'], 'training_history.json')\n",
    "    \n",
    "    if os.path.exists(history_file):\n",
    "        with open(history_file, 'r') as f:\n",
    "            history = json.load(f)\n",
    "        \n",
    "        # Get final epoch performance (could also use best)\n",
    "        final_train_loss = history['train_loss'][-1]\n",
    "        final_train_ssim = history['train_ssim'][-1]\n",
    "        \n",
    "        # For test performance, run inference (shown in next cell)\n",
    "        # For now, use training metrics as proxy\n",
    "        fold_results.append({\n",
    "            'fold': fold['fold_name'],\n",
    "            'test_subject': fold['test'][0],\n",
    "            'train_loss': final_train_loss,\n",
    "            'train_ssim': final_train_ssim\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{fold['fold_name']} (test={fold['test'][0]}):\")\n",
    "        print(f\"  Final train loss: {final_train_loss:.6f}\")\n",
    "        print(f\"  Final train SSIM: {final_train_ssim:.4f}\")\n",
    "    else:\n",
    "        print(f\"\\n{fold['fold_name']}: ‚ùå No results found\")\n",
    "\n",
    "# Find best fold (lowest loss, or highest SSIM)\n",
    "if fold_results:\n",
    "    best_fold = min(fold_results, key=lambda x: x['train_loss'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BEST FOLD (based on training metrics)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Fold: {best_fold['fold']}\")\n",
    "    print(f\"Test subject: {best_fold['test_subject']}\")\n",
    "    print(f\"Train loss: {best_fold['train_loss']:.6f}\")\n",
    "    print(f\"Train SSIM: {best_fold['train_ssim']:.4f}\")\n",
    "    print(\"\\n‚ö†Ô∏è  For proper selection, run inference on each fold's test set\")\n",
    "    print(\"   and select based on test PSNR/SSIM (see next cell)\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd11a1d",
   "metadata": {},
   "source": [
    "## 7. Run Inference on Each Fold's Test Set\n",
    "\n",
    "**Proper model selection requires test set performance:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29fb5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on each fold's test subject\n",
    "print(\"=\"*80)\n",
    "print(\"RUNNING INFERENCE ON TEST SETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for fold in cv_folds:\n",
    "    fold_name = fold['fold_name']\n",
    "    test_subject = fold['test'][0]\n",
    "    \n",
    "    print(f\"\\n{fold_name}: Testing on Subject {test_subject}...\")\n",
    "    \n",
    "    best_model = os.path.join(OUTPUT_DIR, fold_name, f\"{fold_name}_best.pth\")\n",
    "    inference_output = os.path.join(OUTPUT_DIR, fold_name, 'test_inference')\n",
    "    \n",
    "    if os.path.exists(best_model):\n",
    "        !python inference_unet.py \\\n",
    "            --checkpoint \"{best_model}\" \\\n",
    "            --input-dir \"{INPUT_DIR}\" \\\n",
    "            --target-dir \"{TARGET_DIR}\" \\\n",
    "            --output-dir \"{inference_output}\" \\\n",
    "            --file-pattern \"*Subject{test_subject}*.nii\" \\\n",
    "            --compute-metrics\n",
    "        \n",
    "        print(f\"‚úÖ {fold_name} inference complete\")\n",
    "    else:\n",
    "        print(f\"‚ùå Model not found: {best_model}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Check inference output for test set metrics\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde459ce",
   "metadata": {},
   "source": [
    "## 8. Test Best Model on Held-Out Subject\n",
    "\n",
    "After identifying the best fold, test it on the held-out subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf3807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ SELECT BEST FOLD (based on test performance from above)\n",
    "BEST_FOLD_NAME = 'fold1'  # UPDATE THIS after checking test metrics\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"FINAL TEST: {BEST_FOLD_NAME} on Held-Out Subject {HELD_OUT_SUBJECT}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_model = os.path.join(OUTPUT_DIR, BEST_FOLD_NAME, f\"{BEST_FOLD_NAME}_best.pth\")\n",
    "final_test_output = os.path.join(OUTPUT_DIR, 'final_test_heldout')\n",
    "\n",
    "if os.path.exists(best_model):\n",
    "    !python inference_unet.py \\\n",
    "        --checkpoint \"{best_model}\" \\\n",
    "        --input-dir \"{INPUT_DIR}\" \\\n",
    "        --target-dir \"{TARGET_DIR}\" \\\n",
    "        --output-dir \"{final_test_output}\" \\\n",
    "        --file-pattern \"*Subject{HELD_OUT_SUBJECT}*.nii\" \\\n",
    "        --compute-metrics \\\n",
    "        --visualize\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ FINAL TEST COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Best model: {BEST_FOLD_NAME}\")\n",
    "    print(f\"Held-out subject: {HELD_OUT_SUBJECT}\")\n",
    "    print(f\"Results saved to: {final_test_output}\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ùå Model not found: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5769cde",
   "metadata": {},
   "source": [
    "## 9. Summary and Reporting\n",
    "\n",
    "**For your abstract, report:**\n",
    "\n",
    "1. **CV Performance (6 folds):**\n",
    "   - Mean ¬± SD of test metrics across 6 folds\n",
    "   - Example: \"PSNR = 28.5 ¬± 1.2 dB (6-fold CV)\"\n",
    "\n",
    "2. **Held-Out Performance:**\n",
    "   - Best model's performance on Subject 0021\n",
    "   - Example: \"PSNR = 27.8 dB on held-out subject\"\n",
    "\n",
    "3. **Methods:**\n",
    "   - \"6-fold cross-validation on 6 subjects (training: n=5, testing: n=1 per fold)\"\n",
    "   - \"Best model selected based on CV performance\"\n",
    "   - \"Final evaluation on held-out subject (never seen during training)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26816db4",
   "metadata": {},
   "source": [
    "## Tips\n",
    "\n",
    "### Model Selection:\n",
    "- **Don't** use training loss to select best fold\n",
    "- **Do** use test set inference metrics (PSNR/SSIM)\n",
    "- **Option 1:** Highest average test PSNR\n",
    "- **Option 2:** Highest average test SSIM\n",
    "- **Option 3:** Best average rank across metrics\n",
    "\n",
    "### Prevent Disconnection:\n",
    "```javascript\n",
    "// Run in browser console (F12)\n",
    "setInterval(() => {\n",
    "    document.querySelector(\"colab-connect-button\").click()\n",
    "}, 60000)\n",
    "```\n",
    "\n",
    "### Memory Management:\n",
    "- Clear GPU between folds: `torch.cuda.empty_cache()`\n",
    "- Reduce batch size if OOM errors\n",
    "- Monitor with `!nvidia-smi`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ac762",
   "metadata": {},
   "source": [
    "## üì• Download Results\n",
    "\n",
    "After training completes, download your results to continue locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5858ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all results as a ZIP file\n",
    "import shutil\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREPARING RESULTS FOR DOWNLOAD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create ZIP of all results\n",
    "output_zip = \"/content/cross_validation_results.zip\"\n",
    "print(f\"\\nCreating ZIP archive...\")\n",
    "shutil.make_archive(\"/content/cross_validation_results\", 'zip', OUTPUT_DIR)\n",
    "\n",
    "# Get size\n",
    "import os\n",
    "size_mb = os.path.getsize(output_zip) / (1024 * 1024)\n",
    "print(f\"‚úÖ Archive created: {output_zip} ({size_mb:.1f} MB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DOWNLOAD OPTIONS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n1Ô∏è‚É£ Download ZIP file:\")\n",
    "print(\"   Run the next cell to download the ZIP\")\n",
    "print(\"\\n2Ô∏è‚É£ Download individual folders:\")\n",
    "print(\"   Files panel (left) ‚Üí /content/cross_validation_results/\")\n",
    "print(\"   Right-click any folder ‚Üí Download\")\n",
    "print(\"\\n3Ô∏è‚É£ What's included:\")\n",
    "print(\"   ‚Ä¢ fold1/, fold2/, ... fold6/ (best models + configs)\")\n",
    "print(\"   ‚Ä¢ Each fold: ~30-50 MB\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f4c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the ZIP file\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading cross_validation_results.zip...\")\n",
    "print(\"This may take a few minutes depending on the size...\")\n",
    "files.download(output_zip)\n",
    "print(\"‚úÖ Download complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b75dc",
   "metadata": {},
   "source": [
    "## üñ•Ô∏è Continue Locally\n",
    "\n",
    "After downloading, extract and evaluate on your local machine:\n",
    "\n",
    "```bash\n",
    "# Extract the ZIP\n",
    "unzip cross_validation_results.zip -d ./cv_models\n",
    "\n",
    "# Batch evaluate all folds\n",
    "cd synthsup-speechMRI-recon\n",
    "python utils/evaluate_all_folds.py \\\n",
    "    --models-dir ./cv_models \\\n",
    "    --input-dir ../Synth_LR_nii \\\n",
    "    --target-dir ../HR_nii \\\n",
    "    --output-dir ./evaluation_results\n",
    "\n",
    "# Test best model on held-out subject\n",
    "python inference_unet.py \\\n",
    "    --checkpoint ./cv_models/fold2/fold2_best.pth \\\n",
    "    --input-dir ../Synth_LR_nii \\\n",
    "    --target-dir ../HR_nii \\\n",
    "    --output-dir ./inference_results/heldout \\\n",
    "    --file-pattern \"*Subject0021*.nii\" \\\n",
    "    --compute-metrics --visualize\n",
    "```\n",
    "\n",
    "See `docs/COLAB_TO_LOCAL_WORKFLOW.md` for detailed instructions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
