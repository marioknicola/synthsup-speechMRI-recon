# 🎉 Setup Complete - Quick Reference Card

## ✅ What You Now Have

Your repository is fully configured with:

### 📁 **Core Scripts**
- ✅ `sense_reconstruction.py` - Classical SENSE with configurable CLI
- ✅ `unet_model.py` - Complete U-Net architecture (~31M parameters)
- ✅ `dataset.py` - PyTorch data loaders (NIfTI + k-space)
- ✅ `train_unet.py` - Training with separate validation sets
- ✅ `inference_unet.py` - Inference with metrics
- ✅ All utility scripts (PSNR_and_SSIM.py, niftNormaliser.py, etc.)

### 📚 **Documentation**
- ✅ `GETTING_STARTED.md` - Complete beginner tutorial
- ✅ `UNET_ARCHITECTURE.md` - Detailed architecture with diagrams
- ✅ `UNET_README.md` - Quick reference guide
- ✅ `.github/copilot-instructions.md` - AI agent guidelines
- ✅ `requirements.txt` - All dependencies pinned

### 🎯 **Key Features**
- ✅ All outputs save outside repository (to `../`)
- ✅ Training uses `../Synth_LR_nii/` → `../HR_nii/`
- ✅ Validation uses `../Dynamic_SENSE/` → `../Dynamic_SENSE_padded/`
- ✅ Smoke test mode for quick testing
- ✅ TensorBoard integration
- ✅ Resume training from checkpoints
- ✅ Metrics computation (PSNR/SSIM)
- ✅ Visualization generation

---

## 🚀 Quick Start Commands

### 1. Install Dependencies
```bash
cd synthsup-speechMRI-recon/
pip install -r requirements.txt
```

### 2. Verify Setup
```bash
python3 unet_model.py      # Test model
python3 dataset.py          # Test data loading
```

### 3. Train U-Net (80/10/10 split from synthetic pairs)
```bash
python3 train_unet.py \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --output-dir ../outputs \
    --epochs 100 \
    --batch-size 4 \
    --base-filters 32
```

### 4. Monitor Training
```bash
tensorboard --logdir ../outputs/logs
```
Open: http://localhost:6006

### 5. Run Inference
```bash
python3 inference_unet.py \
    --checkpoint ../outputs/checkpoints/best_model.pth \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --output-dir ../reconstructions \
    --compute-metrics \
    --visualize
```

---

## 📊 Expected Data Structure

```
MSc Project/
├── synthsup-speechMRI-recon/    # Repository (code only!)
│   ├── *.py scripts
│   ├── *.md documentation
│   └── requirements.txt
│
├── Synth_LR_nii/                # Training inputs ⭐
├── HR_nii/                      # Training targets ⭐
├── Dynamic_SENSE/               # Validation inputs ⭐
├── Dynamic_SENSE_padded/        # Validation targets ⭐
│
├── kspace_mat_US/               # K-space data
├── sensitivity_maps/            # Coil maps
│
├── outputs/                     # Generated by training
│   ├── checkpoints/
│   └── logs/
│
└── reconstructions/             # Generated by inference
    ├── *.nii
    └── visualizations/
```

---

## ⚠️ Critical Rules

### ❌ NEVER DO THIS:
```bash
# Don't save inside repository
python3 train_unet.py --output-dir ./outputs  # ❌ WRONG
python3 sense_reconstruction.py --output-dir . # ❌ WRONG
```

### ✅ ALWAYS DO THIS:
```bash
# Save to parent directory
python3 train_unet.py --output-dir ../outputs  # ✅ CORRECT
python3 sense_reconstruction.py --output-dir .. # ✅ CORRECT
```

**Why?** 
- Keeps repository clean
- Avoids committing large files
- Follows project conventions
- Prevents git issues

---

## 🛠️ Common Commands

### Training Variants

**Quick test (small model):**
```bash
python3 train_unet.py \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --epochs 10 \
    --batch-size 2 \
    --base-filters 16
```

**Full training (recommended baseline):**
```bash
python3 train_unet.py \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --epochs 100 \
    --batch-size 4 \
    --base-filters 32
```

**Resume training:**
```bash
python3 train_unet.py \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --resume ../outputs/checkpoints/checkpoint_epoch_50.pth
```

### SENSE Reconstruction

**Smoke test:**
```bash
python3 sense_reconstruction.py --smoke-test --plot
```

**Full reconstruction:**
```bash
python3 sense_reconstruction.py \
    --kspace ../kspace_mat_US/kspace_Subject0026_vv.mat \
    --coilmap ../sensitivity_maps/sens_Subject0026_Exam17853_80x82x100_nC22.mat \
    --output-dir .. \
    --subject-id Subject0026_vv
```

### Inference

**Basic:**
```bash
python3 inference_unet.py \
    --checkpoint ../outputs/checkpoints/best_model.pth \
    --input-dir ../Synth_LR_nii \
    --output-dir ../reconstructions
```

**With metrics and visualization:**
```bash
python3 inference_unet.py \
    --checkpoint ../outputs/checkpoints/best_model.pth \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --output-dir ../reconstructions \
    --compute-metrics \
    --visualize \
    --num-vis 10
```

---

## 📖 Documentation Map

| Document | Purpose | When to Read |
|----------|---------|--------------|
| **GETTING_STARTED.md** | Complete tutorial | 🟢 Start here! |
| **UNET_ARCHITECTURE.md** | Deep dive into model | Understanding architecture |
| **UNET_README.md** | Quick reference | Daily usage |
| **.github/copilot-instructions.md** | AI agent guidelines | Contributing code |
| **QUICK_REFERENCE.md** | This file! | Quick lookups |

---

## 🎯 Training Milestones

### After 10 epochs:
- [ ] Training loss decreasing
- [ ] Validation loss tracking training
- [ ] No errors in console
- [ ] TensorBoard showing curves

### After 50 epochs:
- [ ] Validation loss < 0.02
- [ ] PSNR > 28 dB
- [ ] SSIM > 0.80
- [ ] Reconstructions look reasonable

### After 100 epochs:
- [ ] Validation loss converged
- [ ] PSNR > 30 dB
- [ ] SSIM > 0.85
- [ ] High-quality reconstructions

---

## 🚨 Troubleshooting Quick Fixes

| Problem | Solution |
|---------|----------|
| CUDA OOM | `--batch-size 2 --base-filters 16` |
| No files found | Check you're in `synthsup-speechMRI-recon/` |
| Module not found | `pip install -r requirements.txt` |
| Training slow | Check GPU: `nvidia-smi` |
| Loss not decreasing | Try `--lr 5e-4` or `--lr 5e-5` |
| Permission denied | Check output paths use `../` |

---

## 💡 Pro Tips

1. **Always use TensorBoard** - Visual feedback is crucial
2. **Start with smoke test** - Validate before long training
3. **Monitor GPU usage** - `watch -n 1 nvidia-smi`
4. **Save checkpoints frequently** - `--save-freq 5`
5. **Keep training logs** - Copy console output to file
6. **Test on one file first** - Before batch inference
7. **Use absolute paths** - Avoid confusion with relative paths
8. **Check data shapes** - Run `dataset.py` test first

---

## 🎓 Next Steps

### Short Term (Next Few Days)
1. ✅ Read GETTING_STARTED.md fully
2. ✅ Verify all data exists
3. ✅ Run smoke tests
4. ✅ Start training (10 epochs test)
5. ✅ Review first results

### Medium Term (Next Week)
1. Complete 100-epoch training
2. Run full inference on test set
3. Analyze PSNR/SSIM metrics
4. Generate visualizations
5. Compare with SENSE baseline

### Long Term (Project Goals)
1. Experiment with hyperparameters
2. Try different loss weights
3. Add data augmentation
4. Test on new subjects
5. Write up results

---

## 📞 Support Resources

### Documentation
- `GETTING_STARTED.md` - Step-by-step tutorial
- `UNET_ARCHITECTURE.md` - Architecture deep-dive
- `.github/copilot-instructions.md` - Coding guidelines

### Code Tests
```bash
python3 unet_model.py      # Test model
python3 dataset.py          # Test data loading
python3 sense_reconstruction.py --smoke-test  # Test SENSE
```

### Verification Checklist
```bash
# Check Python
python3 --version  # Should be 3.8+

# Check PyTorch
python3 -c "import torch; print(torch.__version__)"

# Check CUDA
python3 -c "import torch; print(torch.cuda.is_available())"

# Check data
ls ../Synth_LR_nii/ | wc -l
ls ../HR_nii/ | wc -l
ls ../Dynamic_SENSE/ | wc -l
ls ../Dynamic_SENSE_padded/ | wc -l
```

---

## ✅ Pre-Flight Checklist

Before training:
- [ ] Installed all dependencies
- [ ] Verified GPU available (if using)
- [ ] Confirmed training data exists (`../Synth_LR_nii/`, `../HR_nii/`)
- [ ] Confirmed validation data exists (`../Dynamic_SENSE/`, `../Dynamic_SENSE_padded/`)
- [ ] Tested model loads (`python3 unet_model.py`)
- [ ] Tested dataset loads (`python3 dataset.py`)
- [ ] Have 10+ GB free disk space
- [ ] Have 10+ GB GPU memory (or patience for CPU)

**All checked?** Ready to train! 🚀

---

## 🎉 Success Criteria

You'll know it's working when you see:

```
Epoch 100 [Train]: 100%|████████| 250/250 [02:15<00:00, 1.85it/s, loss=0.0087]
Epoch 100 [Val]: 100%|██████████| 63/63 [00:30<00:00, 2.07it/s, loss=0.0092]

Epoch 100/100
  Train Loss: 0.0087
  Val Loss:   0.0092
  LR: 0.000025
  Time: 165.3s
--------------------------------------------------------------------------------

Training complete!
Best validation loss: 0.0089
Checkpoints saved to: ../outputs/checkpoints

OVERALL METRICS
Average PSNR: 32.16 dB
Average SSIM: 0.8890
```

**Congratulations! 🎊 Your model is trained and ready!**

---

**Last Updated:** October 27, 2025  
**Repository:** synthsup-speechMRI-recon  
**Author:** Mario Knicola (with AI assistance)
