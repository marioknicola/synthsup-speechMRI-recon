# ğŸ‰ Setup Complete - Quick Reference Card

## âœ… What You Now Have

Your repository is fully configured with:

### ğŸ“ **Core Scripts**
- âœ… `sense_reconstruction.py` - Classical SENSE with configurable CLI
- âœ… `unet_model.py` - Complete U-Net architecture (~31M parameters)
- âœ… `dataset.py` - PyTorch data loaders (NIfTI + k-space)
- âœ… `train_unet.py` - Training with separate validation sets
- âœ… `inference_unet.py` - Inference with metrics
- âœ… All utility scripts (PSNR_and_SSIM.py, niftNormaliser.py, etc.)

### ğŸ“š **Documentation**
- âœ… `GETTING_STARTED.md` - Complete beginner tutorial
- âœ… `UNET_ARCHITECTURE.md` - Detailed architecture with diagrams
- âœ… `UNET_README.md` - Quick reference guide
- âœ… `.github/copilot-instructions.md` - AI agent guidelines
- âœ… `requirements.txt` - All dependencies pinned

### ğŸ¯ **Key Features**
- âœ… All outputs save outside repository (to `../`)
- âœ… Training uses `../Synth_LR_nii/` â†’ `../HR_nii/`
- âœ… Validation uses `../Dynamic_SENSE/` â†’ `../Dynamic_SENSE_padded/`
- âœ… Smoke test mode for quick testing
- âœ… TensorBoard integration
- âœ… Resume training from checkpoints
- âœ… Metrics computation (PSNR/SSIM)
- âœ… Visualization generation

---

## ğŸš€ Quick Start Commands

### 1. Install Dependencies
```bash
cd synthsup-speechMRI-recon/
pip install -r requirements.txt
```

### 2. Verify Setup
```bash
python3 unet_model.py      # Test model
python3 dataset.py          # Test data loading
```

### 3. Train U-Net (80/10/10 split from synthetic pairs)
```bash
python3 train_unet.py \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --output-dir ../outputs \
    --epochs 100 \
    --batch-size 4 \
    --base-filters 32
```

### 4. Monitor Training
```bash
tensorboard --logdir ../outputs/logs
```
Open: http://localhost:6006

### 5. Run Inference
```bash
python3 inference_unet.py \
    --checkpoint ../outputs/checkpoints/best_model.pth \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --output-dir ../reconstructions \
    --compute-metrics \
    --visualize
```

---

## ğŸ“Š Expected Data Structure

```
MSc Project/
â”œâ”€â”€ synthsup-speechMRI-recon/    # Repository (code only!)
â”‚   â”œâ”€â”€ *.py scripts
â”‚   â”œâ”€â”€ *.md documentation
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ Synth_LR_nii/                # Training inputs â­
â”œâ”€â”€ HR_nii/                      # Training targets â­
â”œâ”€â”€ Dynamic_SENSE/               # Validation inputs â­
â”œâ”€â”€ Dynamic_SENSE_padded/        # Validation targets â­
â”‚
â”œâ”€â”€ kspace_mat_US/               # K-space data
â”œâ”€â”€ sensitivity_maps/            # Coil maps
â”‚
â”œâ”€â”€ outputs/                     # Generated by training
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ logs/
â”‚
â””â”€â”€ reconstructions/             # Generated by inference
    â”œâ”€â”€ *.nii
    â””â”€â”€ visualizations/
```

---

## âš ï¸ Critical Rules

### âŒ NEVER DO THIS:
```bash
# Don't save inside repository
python3 train_unet.py --output-dir ./outputs  # âŒ WRONG
python3 sense_reconstruction.py --output-dir . # âŒ WRONG
```

### âœ… ALWAYS DO THIS:
```bash
# Save to parent directory
python3 train_unet.py --output-dir ../outputs  # âœ… CORRECT
python3 sense_reconstruction.py --output-dir .. # âœ… CORRECT
```

**Why?** 
- Keeps repository clean
- Avoids committing large files
- Follows project conventions
- Prevents git issues

---

## ğŸ› ï¸ Common Commands

### Training Variants

**Quick test (small model):**
```bash
python3 train_unet.py \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --epochs 10 \
    --batch-size 2 \
    --base-filters 16
```

**Full training (recommended baseline):**
```bash
python3 train_unet.py \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --epochs 100 \
    --batch-size 4 \
    --base-filters 32
```

**Resume training:**
```bash
python3 train_unet.py \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --resume ../outputs/checkpoints/checkpoint_epoch_50.pth
```

### SENSE Reconstruction

**Smoke test:**
```bash
python3 sense_reconstruction.py --smoke-test --plot
```

**Full reconstruction:**
```bash
python3 sense_reconstruction.py \
    --kspace ../kspace_mat_US/kspace_Subject0026_vv.mat \
    --coilmap ../sensitivity_maps/sens_Subject0026_Exam17853_80x82x100_nC22.mat \
    --output-dir .. \
    --subject-id Subject0026_vv
```

### Inference

**Basic:**
```bash
python3 inference_unet.py \
    --checkpoint ../outputs/checkpoints/best_model.pth \
    --input-dir ../Synth_LR_nii \
    --output-dir ../reconstructions
```

**With metrics and visualization:**
```bash
python3 inference_unet.py \
    --checkpoint ../outputs/checkpoints/best_model.pth \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --output-dir ../reconstructions \
    --compute-metrics \
    --visualize \
    --num-vis 10
```

---

## ğŸ“– Documentation Map

| Document | Purpose | When to Read |
|----------|---------|--------------|
| **GETTING_STARTED.md** | Complete tutorial | ğŸŸ¢ Start here! |
| **UNET_ARCHITECTURE.md** | Deep dive into model | Understanding architecture |
| **UNET_README.md** | Quick reference | Daily usage |
| **.github/copilot-instructions.md** | AI agent guidelines | Contributing code |
| **QUICK_REFERENCE.md** | This file! | Quick lookups |

---

## ğŸ¯ Training Milestones

### After 10 epochs:
- [ ] Training loss decreasing
- [ ] Validation loss tracking training
- [ ] No errors in console
- [ ] TensorBoard showing curves

### After 50 epochs:
- [ ] Validation loss < 0.02
- [ ] PSNR > 28 dB
- [ ] SSIM > 0.80
- [ ] Reconstructions look reasonable

### After 100 epochs:
- [ ] Validation loss converged
- [ ] PSNR > 30 dB
- [ ] SSIM > 0.85
- [ ] High-quality reconstructions

---

## ğŸš¨ Troubleshooting Quick Fixes

| Problem | Solution |
|---------|----------|
| CUDA OOM | `--batch-size 2 --base-filters 16` |
| No files found | Check you're in `synthsup-speechMRI-recon/` |
| Module not found | `pip install -r requirements.txt` |
| Training slow | Check GPU: `nvidia-smi` |
| Loss not decreasing | Try `--lr 5e-4` or `--lr 5e-5` |
| Permission denied | Check output paths use `../` |

---

## ğŸ’¡ Pro Tips

1. **Always use TensorBoard** - Visual feedback is crucial
2. **Start with smoke test** - Validate before long training
3. **Monitor GPU usage** - `watch -n 1 nvidia-smi`
4. **Save checkpoints frequently** - `--save-freq 5`
5. **Keep training logs** - Copy console output to file
6. **Test on one file first** - Before batch inference
7. **Use absolute paths** - Avoid confusion with relative paths
8. **Check data shapes** - Run `dataset.py` test first

---

## ğŸ“ Next Steps

### Short Term (Next Few Days)
1. âœ… Read GETTING_STARTED.md fully
2. âœ… Verify all data exists
3. âœ… Run smoke tests
4. âœ… Start training (10 epochs test)
5. âœ… Review first results

### Medium Term (Next Week)
1. Complete 100-epoch training
2. Run full inference on test set
3. Analyze PSNR/SSIM metrics
4. Generate visualizations
5. Compare with SENSE baseline

### Long Term (Project Goals)
1. Experiment with hyperparameters
2. Try different loss weights
3. Add data augmentation
4. Test on new subjects
5. Write up results

---

## ğŸ“ Support Resources

### Documentation
- `GETTING_STARTED.md` - Step-by-step tutorial
- `UNET_ARCHITECTURE.md` - Architecture deep-dive
- `.github/copilot-instructions.md` - Coding guidelines

### Code Tests
```bash
python3 unet_model.py      # Test model
python3 dataset.py          # Test data loading
python3 sense_reconstruction.py --smoke-test  # Test SENSE
```

### Verification Checklist
```bash
# Check Python
python3 --version  # Should be 3.8+

# Check PyTorch
python3 -c "import torch; print(torch.__version__)"

# Check CUDA
python3 -c "import torch; print(torch.cuda.is_available())"

# Check data
ls ../Synth_LR_nii/ | wc -l
ls ../HR_nii/ | wc -l
ls ../Dynamic_SENSE/ | wc -l
ls ../Dynamic_SENSE_padded/ | wc -l
```

---

## âœ… Pre-Flight Checklist

Before training:
- [ ] Installed all dependencies
- [ ] Verified GPU available (if using)
- [ ] Confirmed training data exists (`../Synth_LR_nii/`, `../HR_nii/`)
- [ ] Confirmed validation data exists (`../Dynamic_SENSE/`, `../Dynamic_SENSE_padded/`)
- [ ] Tested model loads (`python3 unet_model.py`)
- [ ] Tested dataset loads (`python3 dataset.py`)
- [ ] Have 10+ GB free disk space
- [ ] Have 10+ GB GPU memory (or patience for CPU)

**All checked?** Ready to train! ğŸš€

---

## ğŸ‰ Success Criteria

You'll know it's working when you see:

```
Epoch 100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [02:15<00:00, 1.85it/s, loss=0.0087]
Epoch 100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:30<00:00, 2.07it/s, loss=0.0092]

Epoch 100/100
  Train Loss: 0.0087
  Val Loss:   0.0092
  LR: 0.000025
  Time: 165.3s
--------------------------------------------------------------------------------

Training complete!
Best validation loss: 0.0089
Checkpoints saved to: ../outputs/checkpoints

OVERALL METRICS
Average PSNR: 32.16 dB
Average SSIM: 0.8890
```

**Congratulations! ğŸŠ Your model is trained and ready!**

---

**Last Updated:** October 27, 2025  
**Repository:** synthsup-speechMRI-recon  
**Author:** Mario Knicola (with AI assistance)
