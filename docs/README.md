# U-Net for MRI Reconstruction

Complete U-Net deep learning pipeline for synthetically supervised MRI reconstruction with detailed architecture information.

---

## ğŸ¯ Overview

This pipeline learns to reconstruct fully-sampled MRI images from undersampled/aliased inputs using synthetic supervision.

**Training Strategy:**
- **Input:** Synthetically undersampled images (`Synth_LR_nii/`)
- **Target:** Fully-sampled high-resolution images (`HR_nii/`)
- **Test:** Real dynamic SENSE data (`Dynamic_SENSE_padded/`)

**Key Components:**
- `unet_model.py` - U-Net architecture - `dataset.py` - PyTorch data loaders with [0,1] normalization
- `train_unet.py` - Training script with L1+SSIM loss
- `inference_unet.py` - Inference with metrics and visualization

---

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Train the Model

```bash
python3 train_unet.py \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --epochs 200 \
    --batch-size 4 \
    --base-filters 32
```

**Outputs:**
- `../outputs/checkpoints/best_model.pth` - Best model
- `../outputs/training.log` - Training history
- `../outputs/test_indices.txt` - Test set split

**Monitor training:**
```bash
tensorboard --logdir ../outputs/logs
```

### 3. Run Inference

```bash
python3 inference_unet.py \
    --checkpoint ../outputs/checkpoints/best_model.pth \
    --input-dir ../Dynamic_SENSE_padded_95f \
    --output-dir ../reconstructions \
    --compute-metrics \
    --visualize
```

---

### Parameter Configuration

```python
# Lightweight baseline (default)
model = UNet(in_channels=1, out_channels=1, base_filters=32)


# Heavier variant
model = UNet(in_channels=1, out_channels=1, base_filters=64)

```

### Layer Dimensions

For input shape `(1, 312, 410)` with `base_filters=32`:

| Layer | Shape | Channels | Parameters | Notes |
|-------|-------|----------|------------|-------|
| **Input** | (1, 312, 410) | 1 | - | Normalized [0,1] |
| **Inc** | (32, 312, 410) | 32 | 1,856 | Initial features |
| **Down1** | (64, 156, 205) | 64 | 37,376 | Ã—1/2 resolution |
| **Down2** | (128, 78, 102) | 128 | 148,224 | Ã—1/4 resolution |
| **Down3** | (256, 39, 51) | 256 | 591,360 | Ã—1/8 resolution |
| **Down4** | (256, 19, 25) | 256 | 591,360 | Ã—1/16 (bottleneck) |
| **Up1** | (128, 39, 51) | 128 | 591,360 | Ã—1/8 resolution |
| **Up2** | (64, 78, 102) | 64 | 148,224 | Ã—1/4 resolution |
| **Up3** | (32, 156, 205) | 32 | 37,376 | Ã—1/2 resolution |
| **Up4** | (32, 312, 410) | 32 | 18,752 | Full resolution |
| **Output** | (1, 312, 410) | 1 | 33 | Final prediction |
---
^^^ this doesn't include the batch size


## ğŸ“ Training Details

### Data Normalization

**Per-file [0, 1] normalization** (automatic):
- Computes min/max statistics for entire file at initialization
- All frames from same file use same normalization
- Prevents frame-to-frame intensity variations
- Automatic denormalization during inference

**Benefits:**
- Solves 4.8Ã— intensity mismatch between datasets
- Prevents negative values in predictions
- Stable gradients during training
- Better generalization to test data

### Loss Function

Combined L1 + SSIM loss:

```python
Loss = 0.70 Ã— L1(pred, target) + 0.16 Ã— SSIM_loss(pred, target)
```

- **L1 Loss:** Pixel-wise accuracy
- **SSIM Loss:** Perceptual quality and structure preservation
- **Balance:** Prevents blurry outputs while maintaining fidelity

### Training Configuration

Default settings (80/10/10 split):
```bash
python3 train_unet.py \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --epochs 100 \
    --batch-size 4 \
    --lr 1e-4 \
    --base-filters 32 \
    --output-dir ../outputs
```

Advanced options:
```bash
# Longer training
--epochs 200

# Larger model
--base-filters 64 --batch-size 2

# Different loss balance
--alpha 0.5  # 50% L1, 50% SSIM

# Lower learning rate
--lr 5e-5
```

### Resume Training

```bash
python3 train_unet.py \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --resume ../outputs/checkpoints/latest_model.pth \
    --epochs 200
```

---

## ğŸ“Š Expected Results

### Training Metrics (After 100 Epochs)

| Metric | Initial | After Training |
|--------|---------|----------------|
| **Val PSNR** | ~16 dB | **27-32 dB** |
| **Val SSIM** | ~0.22 | **0.75-0.85** |
| **Val Loss** | ~0.20 | **0.05-0.10** |
| **Training Time** | - | 2-4 hours (GPU) |

### Improvements Over Zero-Filled

- âœ… Reduced aliasing artifacts
- âœ… Better edge preservation
- âœ… Improved SNR
- âœ… More natural appearance

---

## ğŸ”§ Advanced Features

## ğŸ—‚ï¸ Directory Structure

```
MSc Project/
â”œâ”€â”€ synthsup-speechMRI-recon/        # Repository (code only)
â”‚   â”œâ”€â”€ unet_model.py
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ train_unet.py
â”‚   â”œâ”€â”€ train_cross_validation.py
â”‚   â”œâ”€â”€ inference_unet.py
â”‚   â”œâ”€â”€ remove_first_5_frames.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ evaluate_all_folds.py
â”‚   â”‚   â””â”€â”€ download_colab_models.py
â”‚   â””â”€â”€ docs/
â”‚
â”œâ”€â”€ Synth_LR_nii/                    # Training input
â”œâ”€â”€ HR_nii/                          # Training target
â”œâ”€â”€ Dynamic_SENSE_padded_95f/        # Test data (95 frames)
â”‚
â”œâ”€â”€ cv_models/                       # Cross-validation models
â”‚   â”œâ”€â”€ fold1/
â”‚   â”œâ”€â”€ fold2/
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ fold6/
â”‚
â”œâ”€â”€ evaluation_results/              # CV evaluation results
â”‚   â”œâ”€â”€ fold1/
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ cv_summary.json
â”‚
â”œâ”€â”€ inference_results/               # Inference outputs
â”‚   â””â”€â”€ heldout_0021/
â”‚
â”œâ”€â”€ outputs/                         # Training outputs
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â””â”€â”€ latest_model.pth
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ training.log
â”‚
â””â”€â”€ reconstructions/                 # Inference outputs
```

**âš ï¸ Important:** Never save outputs inside the repository folder!

---

## ğŸ§ª Testing

### Quick Model Test
```bash
python3 unet_model.py
```

### Quick Dataset Test
```bash
python3 dataset.py
```

### Full Inference Test
```bash
python3 inference_unet.py \
    --checkpoint ../outputs/checkpoints/best_model.pth \
    --input-dir ../Synth_LR_nii \
    --target-dir ../HR_nii \
    --output-dir ../reconstructions_test \
    --compute-metrics \
    --visualize
```

---

## ğŸ” Troubleshooting

### CUDA Out of Memory

Reduce batch size or model size:
```bash
python3 train_unet.py --batch-size 2 --base-filters 16 ...
```

### Dataset Not Found

Verify data structure:
```bash
ls ../Synth_LR_nii/*.nii | wc -l 
ls ../HR_nii/*.nii | wc -l         
```

## ğŸ“š See Also

- **[GETTING_STARTED.md](GETTING_STARTED.md)** - Step-by-step tutorial
- **[USE_IN_COLAB.md](USE_IN_COLAB.md)** - Google Colab training guide
- **[INFERENCE.md](INFERENCE.md)** - Inference and evaluation guide
- **[DATA_CONSISTENCY.md](DATA_CONSISTENCY.md)** - Physics-based constraints
- **[CHANGELOG.md](CHANGELOG.md)** - Version history

